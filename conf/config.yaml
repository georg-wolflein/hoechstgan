defaults:
  - _self_
  - dataset@dataset.input: h3342
  - dataset@dataset.outputs.B: default

name: experiment
wandb_id:
is_train: true
phase: train
initial_epoch: 0 # where to start counting epochs
load_checkpoint: # (epoch |Â latest | null) if specified, will load checkpoint (if epoch, will use initial_epoch's checkpoint) and continue training from there
data_folder: ${oc.env:DATA_FOLDER,/Users/georg/Desktop/Scratch.nosync}
checkpoints_dir: ${data_folder}/checkpoints
dataset:
  data_root: ${data_folder}/patches
  input:
    props: # key-value pairs to identify images
    transforms: []
    num_channels: 1
  outputs:
    B:
      props: # key-value pairs to identify images
      transforms: []
      num_channels: 1
    # C:
    #   props: # key-value pairs to identify images
    #   transforms: []
    #   num_channels: 1
  batch_size: 1
  shuffle: true
  num_threads: 4 # number of threads for loading data
  max_size: .inf
  split:
    train: 90
    val: 0
    test: 10
norm: batch
initialization: normal
initialization_scale: .02 # scaling factor
gpus: [0]
learning_rate:
  initial: 0.0002
  policy: linear # learning rate policy: linear | step | plateau | cosine
  n_epochs_initial: 20 # number of epochs with the initial learning rate 
  n_epochs_decay: 10 # number of epochs to linearly decay learning rate to zero
  decay_iters: 50  # multiply by a gamma every decay_iters iterations                                                                                                                                                                          
beta1: .5
gan: pix2pix
discriminator:
  filters: 64
  layers: 3
generator:
  filters: 64
  dropout: true
  learn_C_from_B: false
loss:
  generator:
    ground_truth:
      l1: 100.0
      l2: 0.0
      kl: 0.0
verbose: true
log_freq: 100 # log metrics every n iterations
visualize_freq: 5000 # log visualizations every n iterations, must be a multiple of log_freq
save_epoch_freq: 1
save_latest_freq: 5000 
save_by_iter: false # if false, save only the latest model